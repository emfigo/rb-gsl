<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE html 
     PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
     "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>File: nonlinearfit.rdoc</title>
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
  <meta http-equiv="Content-Script-Type" content="text/javascript" />
  <link rel="stylesheet" href="../.././rdoc-style.css" type="text/css" media="screen" />
  <script type="text/javascript">
  // <![CDATA[

  function popupCode( url ) {
    window.open(url, "Code", "resizable=yes,scrollbars=yes,toolbar=no,status=no,height=150,width=400")
  }

  function toggleCode( id ) {
    if ( document.getElementById )
      elem = document.getElementById( id );
    else if ( document.all )
      elem = eval( "document.all." + id );
    else
      return false;

    elemStyle = elem.style;
    
    if ( elemStyle.display != "block" ) {
      elemStyle.display = "block"
    } else {
      elemStyle.display = "none"
    }

    return true;
  }
  
  // Make codeblocks hidden by default
  document.writeln( "<style type=\"text/css\">div.method-source-code { display: none }</style>" )
  
  // ]]>
  </script>

</head>
<body>



  <div id="fileHeader">
    <h1>nonlinearfit.rdoc</h1>
    <table class="header-table">
    <tr class="top-aligned-row">
      <td><strong>Path:</strong></td>
      <td>rdoc/nonlinearfit.rdoc
      </td>
    </tr>
    <tr class="top-aligned-row">
      <td><strong>Last Update:</strong></td>
      <td>Sun Nov 14 14:53:48 -0800 2010</td>
    </tr>
    </table>
  </div>
  <!-- banner header -->

  <div id="bodyContent">



  <div id="contextContent">

    <div id="description">
      <h1>Nonlinear Least-Squares Fitting</h1>
<p>
This chapter describes functions for multidimensional nonlinear
least-squares fitting. The library provides low level components for a
variety of iterative solvers and convergence tests. These can be combined
by the user to achieve the desired solution, with full access to the
intermediate steps of the iteration. Each class of methods uses the same
framework, so that you can switch between solvers at runtime without
needing to recompile your program. Each instance of a solver keeps track of
its own state, allowing the solvers to be used in multi-threaded programs.
</p>
<p>
Contents:
</p>
<ol>
<li><a href="nonlinearfit_rdoc.html#1">Overview</a>

</li>
<li><a href="nonlinearfit_rdoc.html#2">Initializing the Solver</a>

<ol>
<li><a href="nonlinearfit_rdoc.html#2.1">GSL::MultiFit::FdfSolver class</a>

</li>
</ol>
</li>
<li><a href="nonlinearfit_rdoc.html#3">Providing the function to be
minimized</a>

<ol>
<li><a href="nonlinearfit_rdoc.html#3.1">GSL::MultiFit::Function_fdf class</a>

</li>
</ol>
</li>
<li><a href="nonlinearfit_rdoc.html#4">Iteration</a>

</li>
<li><a href="nonlinearfit_rdoc.html#5">Search Stopping Parameters</a>

</li>
<li><a href="nonlinearfit_rdoc.html#6">Computing the covariance matrix of best
fit parameters</a>

</li>
<li><a href="nonlinearfit_rdoc.html#7">Higher level interfaces</a>

</li>
<li><a href="nonlinearfit_rdoc.html#8">Examples</a>

<ol>
<li><a href="nonlinearfit_rdoc.html#8.1">Fitting to user-defined functions</a>

</li>
<li><a href="nonlinearfit_rdoc.html#8.2">Fitting to built-in functions</a>

</li>
</ol>
</li>
</ol>
<h2><a href="../.././index.html"name="1"></a> Overview</h2>
<p>
The problem of multidimensional nonlinear least-squares fitting requires
the minimization of the squared residuals of n functions, f_i, in p
parameters, x_i, All algorithms proceed from an initial guess using the
linearization, where x is the initial point, p is the proposed step and J
is the Jacobian matrix J_{ij} = d f_i / d x_j. Additional strategies are
used to enlarge the region of convergence. These include requiring a
decrease in the norm ||F|| on each step or using a trust region to avoid
steps which fall outside the linear regime.
</p>
<p>
To perform a weighted least-squares fit of a nonlinear model Y(x,t) to data
(t_i, y_i) with independent gaussian errors \sigma_i, use function
components of the following form, Note that the model parameters are
denoted by x in this chapter since the non-linear least-squares algorithms
are described geometrically (i.e. finding the minimum of a surface). The
independent variable of any data to be fitted is denoted by t.
</p>
<p>
With the definition above the Jacobian is J_{ij} =(1 / \sigma_i) d Y_i / d
x_j, where Y_i = Y(x,t_i).
</p>
<h2><a href="../.././index.html"name="2"></a> Initializing the Solver</h2>
<h3><a href="../.././index.html"name="2.1"></a> GSL::MultiFit::FdfSolver class</h3>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::FdfSolver.alloc(T, n, p)

<p>
This creates an instance of the <tt>GSL::MultiFit::FdfSolver</tt> class of
type <tt>T</tt> for <tt>n</tt> observations and <tt>p</tt> parameters. The
type <tt>T</tt> is given by a <tt>Fixnum</tt> constant or a
<tt>String</tt>,
</p>
<ul>
<li><tt>GSL::MultiFit::LMSDER</tt> or <tt>&quot;lmsder&quot;</tt>

</li>
<li><tt>GSL::MultiFit::LMDER</tt> or <tt>&quot;lmder&quot;</tt>

</li>
</ul>
<p>
For example, the following code creates an instance of a
Levenberg-Marquardt solver for 100 data points and 3 parameters,
</p>
<pre>
    solver = MultiFit::FdfSolver.alloc(MultiFit::LMDER, 100, 3)
</pre>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::FdfSolver#set(f, x)

<p>
This method initializes, or reinitializes, an existing solver <tt>self</tt>
to use the function <tt>f</tt> and the initial guess <tt>x</tt>. The
function <tt>f</tt> is an instance of the
<tt>GSL::MultiFit::Function_fdf</tt> class (see below). The initial guess
of the parameters <tt>x</tt> is given by a <a
href="vector_rdoc.html">GSL::Vector</a> object.
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::FdfSolver#name

<p>
This returns the name of the solver <tt>self</tt> as a String.
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::FdfSolver#x

</li>
<li>GSL::MultiFit::FdfSolver#dx

</li>
<li>GSL::MultiFit::FdfSolver#f

</li>
<li>GSL::MultiFit::FdfSolver#J

</li>
<li>GSL::MultiFit::FdfSolver#jacobian

</li>
<li>GSL::MultiFit::FdfSolver#jac

<p>
Access to the members (see <tt>gsl_multifit_nlin.h</tt>)
</p>
</li>
</ul>
<h2><a href="../.././index.html"name="3"></a> Providing the function to be minimized</h2>
<h3><a href="../.././index.html"name="3.1"></a> GSL::MultiFit::Function_fdf class</h3>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::Function_fdf.alloc()

</li>
<li>GSL::MultiFit::Function_fdf.alloc(f, df, p)

</li>
<li>GSL::MultiFit::Function_fdf.alloc(f, df, fdf, p)

<p>
Constructor for the <tt>Function_fdf</tt> class, to a function with
<tt>p</tt> parameters, The first two or three arguments are Ruby Proc
objects to evaluate the function to minimize and its derivative (Jacobian).
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::Function_fdf#set_procs(f, df, p)

</li>
<li>GSL::MultiFit::Function_fdf#set_procs(f, df, fdf, p)

<p>
This initialize of reinitialize the function <tt>self</tt> with <tt>p</tt>
parameters by two or three Proc objects <tt>f, df</tt> and <tt>fdf</tt>.
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::Function_fdf#set_data(t, y)

</li>
<li>GSL::MultiFit::Function_fdf#set_data(t, y, sigma)

<p>
This sets the data <tt>t, y, sigma</tt> of length <tt>n</tt>, to the
function <tt>self</tt>.
</p>
</li>
</ul>
<h2><a href="../.././index.html"name="4"></a> Iteration</h2>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::FdfSolver#iterate

<p>
THis performs a single iteration of the solver <tt>self</tt>. If the
iteration encounters an unexpected problem then an error code will be
returned. The solver maintains a current estimate of the best-fit
parameters at all times. This information can be accessed with the method
<tt>position</tt>.
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::FdfSolver#position

<p>
This returns the current position (i.e. best-fit parameters) of the solver
<tt>self</tt>, as a <tt>GSL::Vector</tt> object.
</p>
</li>
</ul>
<h2><a href="../.././index.html"name="5"></a> Search Stopping Parameters</h2>
<p>
A minimization procedure should stop when one of the following conditions
is true:
</p>
<ul>
<li>A minimum has been found to within the user-specified precision.

</li>
<li>A user-specified maximum number of iterations has been reached.

</li>
<li>An error has occurred.

</li>
</ul>
<p>
The handling of these conditions is under user control. The method below
allows the user to test the current estimate of the best-fit parameters.
</p>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::FdfSolver#test_delta(epsabs, epsrel)

<p>
This method tests for the convergence of the sequence by comparing the last
step with the absolute error <tt>epsabs</tt> and relative error
(<tt>epsrel</tt> to the current position. The test returns
<tt>GSL::SUCCESS</tt> if the following condition is achieved,
</p>
<pre>
  |dx_i| &lt; epsabs + epsrel |x_i|
</pre>
<p>
for each component of <tt>x</tt> and returns <tt>GSL::CONTINUE</tt>
otherwise.
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::FdfSolver#test_gradient(g, epsabs)

</li>
<li>GSL::MultiFit::FdfSolver#test_gradient(epsabs)

<p>
This function tests the residual gradient <tt>g</tt> against the absolute
error bound <tt>epsabs</tt>. If <tt>g</tt> is not given, it is calculated
internally. Mathematically, the gradient should be exactly zero at the
minimum. The test returns <tt>GSL::SUCCESS</tt> if the following condition
is achieved,
</p>
<pre>
  \sum_i |g_i| &lt; epsabs
</pre>
<p>
and returns <tt>GSL::CONTINUE</tt> otherwise. This criterion is suitable
for situations where the precise location of the minimum, x, is unimportant
provided a value can be found where the gradient is small enough.
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::FdfSolver#gradient

<p>
This method returns the gradient g of \Phi(x) = (1/2) ||F(x)||^2 from the
Jacobian matrix and the function values, using the formula g = J^T f.
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiFit.test_delta(dx, x, epsabs, epsrel)

</li>
<li>GSL::MultiFit.test_gradient(g, epsabs)

</li>
<li>GSL::MultiFit.gradient(jac, f, g)

</li>
<li>GSL::MultiFit.covar(jac, epsrel)

</li>
<li>GSL::MultiFit.covar(jac, epsrel, covar)

<p>
Singleton methods of the <tt>GSL::MultiFit</tt> module.
</p>
</li>
</ul>
<h2><a href="../.././index.html"name="6"></a> Computing the covariance matrix of best fit parameters</h2>
<hr size="1"></hr><ul>
<li>GSL::MultiFit.covar(J, epsrel)

</li>
<li>GSL::MultiFit.covar(J, epsrel, covar)

<p>
This method uses the Jacobian matrix <tt>J</tt> to compute the covariance
matrix of the best-fit parameters. If an existing matrix <tt>covar</tt> is
given, it is overwritten, and if not, this method returns a new matrix. The
parameter <tt>epsrel</tt> is used to remove linear-dependent columns when
<tt>J</tt> is rank deficient.
</p>
<p>
The covariance matrix is given by,
</p>
<pre>
   covar = (J^T J)^{-1}
</pre>
<p>
and is computed by QR decomposition of <tt>J</tt> with column-pivoting. Any
columns of R which satisfy
</p>
<pre>
  |R_{kk}| &lt;= epsrel |R_{11}|
</pre>
<p>
are considered linearly-dependent and are excluded from the covariance
matrix (the corresponding rows and columns of the covariance matrix are set
to zero).
</p>
</li>
</ul>
<h2><a href="../.././index.html"name="7"></a> Higher level interfaces</h2>
<hr size="1"></hr><ul>
<li>GSL::MultiFit::FdfSolver.fit(x, y, type[, guess])

</li>
<li>GSL::MultiFit::FdfSolver.fit(x, w, y, type[, guess])

<p>
This method uses <tt>FdfSolver</tt> with the LMSDER algorithm to fit the
data <tt>[x, y]</tt> to a function of type <tt>type</tt>. The returned
value is an array of 4 elements, <tt>[coef, err, chisq, dof]</tt>, where
<tt>coef</tt> is an array of the fitting coefficients, <tt>err</tt>
contains errors in estimating <tt>coef</tt>, <tt>chisq</tt> is the
chi-squared, and <tt>dof</tt> is the degree-of-freedom in the fitting which
equals to (data length - number of fitting coefficients). The optional
argument <tt>guess</tt> is an array of initial guess of the coefficients.
The fitting type <tt>type</tt> is given by a <tt>String</tt> as follows.
</p>
<ul>
<li><tt>&quot;gaussian&quot;</tt>: Gaussian fit, <tt>y = y0 + A
exp(-(x-x0)^2/2/var)</tt>, <tt>coef = [y0, A, x0, var]</tt>

</li>
<li><tt>&quot;gaussian_2peaks&quot;</tt>: 2-peak Gaussian fit, <tt>y = y0 + A1
exp(-(x-x1)^2/2/var1) + A2 exp(-(x-x2)^2/2/var2)</tt>, <tt>coef = [y0, A1,
x1, var1, A2, x2, var2]</tt>

</li>
<li><tt>&quot;exp&quot;</tt>: Exponential fit, <tt>y = y0 + A exp(-b x)</tt>,
<tt>coef = [y0, A, b]</tt>

</li>
<li><tt>&quot;dblexp&quot;</tt>: Double exponential fit, <tt>y = y0 + A1
exp(-b1 x) + A2 exp(-b2 x)</tt>, <tt>coef = [y0, A1, b1, A2, b2]</tt>

</li>
<li><tt>&quot;sin&quot;</tt>: Sinusoidal fit, <tt>y = y0 + A sin(f x +
phi)</tt>, <tt>coef = [y0, A, f, phi]</tt>

</li>
<li><tt>&quot;lor&quot;</tt>: Lorentzian peak fit, <tt>y = y0 + A/((x-x0)^2 +
B)</tt>, <tt>coef = [y0, A, x0, B]</tt>

</li>
<li><tt>&quot;hill&quot;</tt>: Hill&#8216;s equation fit, <tt>y = y0 + (m -
y0)/(1 + (xhalf/x)^r)</tt>, <tt>coef = [y0, n, xhalf, r]</tt>

</li>
<li><tt>&quot;sigmoid&quot;</tt>: Sigmoid (Fermi-Dirac) function fit, <tt>y =
y0 + m/(1 + exp((x0-x)/r))</tt>, <tt>coef = [y0, m, x0, r]</tt>

</li>
<li><tt>&quot;power&quot;</tt>: Power-law fit, <tt>y = y0 + A x^r</tt>,
<tt>coef = [y0, A, r]</tt>

</li>
<li><tt>&quot;lognormal&quot;</tt>: Lognormal peak fit, <tt>y = y0 + A exp[
-(log(x/x0)/width)^2 ]</tt>, <tt>coef = [y0, A, x0, width]</tt>

</li>
</ul>
<p>
See <a href="fit_rdoc.html#2.3">Linear fitting</a> for linear and
polynomical fittings.
</p>
</li>
</ul>
<h2><a href="../.././index.html"name="8"></a> Examples</h2>
<h3><a href="../.././index.html"name="8.1"></a> Fitting to user-defined functions</h3>
<p>
The following example program fits a weighted exponential model with
background to experimental data, Y = A exp(-lambda t) + b. The first part
of the program sets up the functions <tt>procf</tt> and <tt>procdf</tt> to
calculate the model and its Jacobian. The appropriate fitting function is
given by,
</p>
<pre>
  f_i = ((A exp(-lambda t_i) + b) - y_i)/sigma_i
</pre>
<p>
where we have chosen t_i = i. The Jacobian matrix <tt>jac</tt> is the
derivative of these functions with respect to the three parameters (A,
lambda, b). It is given by,
</p>
<pre>
  J_{ij} = d f_i / d x_j
</pre>
<p>
where x_0 = A, x_1 = lambda and x_2 = b.
</p>
<pre>
  require(&quot;gsl&quot;)
  include GSL::MultiFit

  # x: Vector, list of the parameters to determine
  # t, y, sigma: Vectors, observational data
  # f: Vector, function to minimize
  procf = Proc.new { |x, t, y, sigma, f|
    a = x[0]
    lambda = x[1]
    b = x[2]
    n = t.size
    for i in 0...n do
      yi = a*Math::exp(-lambda*t[i]) + b
      f[i] = (yi - y[i])/sigma[i]
    end
  }

  # jac: Matrix, Jacobian
  procdf = Proc.new { |x, t, y, sigma, jac|
    a = x[0]
    lambda = x[1]
    n = t.size
    for i in 0...n do
      ti = t[i]
      si = sigma[i]
      ei = Math::exp(-lambda*ti)
      jac.set(i, 0, ei/si)
      jac.set(i, 1, -ti*a*ei/si)
      jac.set(i, 2, 1.0/si)
    end
  }

  f = GSL::MultiFit::Function_fdf.alloc(procf, procdf, 2)

  # Create data
  r = GSL::Rng.alloc()
  t = GSL::Vector.alloc(n)
  y = GSL::Vector.alloc(n)
  sigma = Vector.alloc(n)
  for i in 0...n do
    t[i] = i
    y[i] = 1.0 + 5*Math::exp(-0.1*t[i]) + r.gaussian(0.1)
    sigma[i] = 0.1
  end

  f.set_data(t, y, sigma)
  x = GSL::Vector.alloc(1.0, 0.0, 0.0)    # initial guess

  solver = GSL::FdfSolver.alloc(FdfSolver::LMSDER, n, np)

  solver.set(f, x)

  iter = 0
  solver.print_state(iter)
  begin
    iter += 1
    status = solver.iterate
    solver.print_state(iter)
    status = solver.test_delta(1e-4, 1e-4)
  end while status == GSL::CONTINUE and iter &lt; 500

  covar = solver.covar(0.0)
  position = solver.position
  chi2 = pow_2(solver.f.dnrm2)
  dof = n - np
  printf(&quot;A      = %.5f +/- %.5f\n&quot;, position[0], Math::sqrt(chi2/dof*covar[0][0]))
  printf(&quot;lambda = %.5f +/- %.5f\n&quot;, position[1], Math::sqrt(chi2/dof*covar[1][1]))
  printf(&quot;b      = %.5f +/- %.5f\n&quot;, position[2], Math::sqrt(chi2/dof*covar[2][2]))
</pre>
<h3><a href="../.././index.html"name="8.2"></a> Fitting to built-in functions</h3>
<pre>
  #!/usr/bin/env ruby
  require(&quot;gsl&quot;)
  include MultiFit

  N = 100

  y0 = 1.0
  A = 2.0
  x0 = 3.0
  w = 0.5

  r = Rng.alloc
  x = Vector.linspace(0.01, 10, N)
  sig = 1
  # Lognormal function with noise
  y =  y0 + A*Sf::exp(-pow_2(Sf::log(x/x0)/w)) + 0.1*Ran::gaussian(r, sig, N)

  guess = [0, 3, 2, 1]
  coef, err, chi2, dof = MultiFit::FdfSolver.fit(x, y, &quot;lognormal&quot;, guess)
  y0 = coef[0]
  amp = coef[1]
  x0 = coef[2]
  w = coef[3]

  graph(x, y, y0+amp*Sf::exp(-pow_2(Sf::log(x/x0)/w)))
</pre>
<p>
<a href="fit_rdoc.html">prev</a> <a href="bspline_rdoc.html">next</a>
</p>
<p>
<a href="ref_rdoc.html">Reference index</a> <a
href="index_rdoc.html">top</a>
</p>

    </div>


   </div>


  </div>


    <!-- if includes -->

    <div id="section">





      


    <!-- if method_list -->


  </div>


<div id="validator-badges">
  <p><small><a href="http://validator.w3.org/check/referer">[Validate]</a></small></p>
</div>

</body>
</html>