<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE html 
     PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
     "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>File: multimin.rdoc</title>
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
  <meta http-equiv="Content-Script-Type" content="text/javascript" />
  <link rel="stylesheet" href="../.././rdoc-style.css" type="text/css" media="screen" />
  <script type="text/javascript">
  // <![CDATA[

  function popupCode( url ) {
    window.open(url, "Code", "resizable=yes,scrollbars=yes,toolbar=no,status=no,height=150,width=400")
  }

  function toggleCode( id ) {
    if ( document.getElementById )
      elem = document.getElementById( id );
    else if ( document.all )
      elem = eval( "document.all." + id );
    else
      return false;

    elemStyle = elem.style;
    
    if ( elemStyle.display != "block" ) {
      elemStyle.display = "block"
    } else {
      elemStyle.display = "none"
    }

    return true;
  }
  
  // Make codeblocks hidden by default
  document.writeln( "<style type=\"text/css\">div.method-source-code { display: none }</style>" )
  
  // ]]>
  </script>

</head>
<body>



  <div id="fileHeader">
    <h1>multimin.rdoc</h1>
    <table class="header-table">
    <tr class="top-aligned-row">
      <td><strong>Path:</strong></td>
      <td>rdoc/multimin.rdoc
      </td>
    </tr>
    <tr class="top-aligned-row">
      <td><strong>Last Update:</strong></td>
      <td>Sun Nov 14 14:53:48 -0800 2010</td>
    </tr>
    </table>
  </div>
  <!-- banner header -->

  <div id="bodyContent">



  <div id="contextContent">

    <div id="description">
      <h1>Multidimensional Minimization</h1>
<p>
This chapter describes routines for finding minima of arbitrary
multidimensional functions. The library provides low level components for a
variety of iterative minimizers and convergence tests. These can be
combined by the user to achieve the desired solution, while providing full
access to the intermediate steps of the algorithms. Each class of methods
uses the same framework, so that you can switch between minimizers at
runtime without needing to recompile your program. Each instance of a
minimizer keeps track of its own state, allowing the minimizers to be used
in multi-threaded programs.
</p>
<p>
Contents:
</p>
<ol>
<li><a href="multimin_rdoc.html#1">Overview</a>

</li>
<li><a href="multimin_rdoc.html#2">Caveats</a>

</li>
<li><a href="multimin_rdoc.html#3">Initializing the Multidimensional
Minimizer</a>

</li>
<li><a href="multimin_rdoc.html#4">Providing a function to minimize</a>

</li>
<li><a href="multimin_rdoc.html#5">Iteration</a>

</li>
<li><a href="multimin_rdoc.html#6">Stopping Criteria</a>

</li>
<li><a href="multimin_rdoc.html#7">Examples</a>

<ol>
<li><a href="multimin_rdoc.html#7.1">FdfMinimizer</a>

</li>
<li><a href="multimin_rdoc.html#7.2">FMinimizer</a>

</li>
</ol>
</li>
</ol>
<h2><a href="../.././index.html"name="1"></a> Overview</h2>
<p>
The problem of multidimensional minimization requires finding a point x
such that the scalar function, takes a value which is lower than at any
neighboring point. For smooth functions the gradient g = \nabla f vanishes
at the minimum. In general there are no bracketing methods available for
the minimization of n-dimensional functions. The algorithms proceed from an
initial guess using a search algorithm which attempts to move in a downhill
direction.
</p>
<p>
Algorithms making use of the gradient of the function perform a
one-dimensional line minimisation along this direction until the lowest
point is found to a suitable tolerance. The search direction is then
updated with local information from the function and its derivatives, and
the whole process repeated until the true n-dimensional minimum is found.
</p>
<p>
The Nelder-Mead Simplex algorithm applies a different strategy. It
maintains n+1 trial parameter vectors as the vertices of a n-dimensional
simplex. In each iteration step it tries to improve the worst vertex by a
simple geometrical transformation until the size of the simplex falls below
a given tolerance.
</p>
<p>
Both types of algorithms use a standard framework. The user provides a
high-level driver for the algorithms, and the library provides the
individual functions necessary for each of the steps. There are three main
phases of the iteration. The steps are,
</p>
<ul>
<li>initialize minimizer state, s, for algorithm T

</li>
<li>update s using the iteration T

</li>
<li>test s for convergence, and repeat iteration if necessary

</li>
</ul>
<p>
Each iteration step consists either of an improvement to the
line-minimisation in the current direction or an update to the search
direction itself. The state for the minimizers is held in a
<tt>GSL::MultiMin::FdfMinimizer</tt> or a
<tt>GSL::MultiMin::FMinimizer</tt> object.
</p>
<h2><a href="../.././index.html"name="2"></a> Caveats</h2>
<p>
Note that the minimization algorithms can only search for one local minimum
at a time. When there are several local minima in the search area, the
first minimum to be found will be returned; however it is difficult to
predict which of the minima this will be. In most cases, no error will be
reported if you try to find a local minimum in an area where there is more
than one.
</p>
<p>
It is also important to note that the minimization algorithms find local
minima; there is no way to determine whether a minimum is a global minimum
of the function in question.
</p>
<h2><a href="../.././index.html"name="3"></a> Initializing the Multidimensional Minimizer</h2>
<hr size="1"></hr><ul>
<li>GSL::MultiMin::FdfMinimizer.alloc(type, n)

</li>
<li>GSL::MultiMin::FMinimizer.alloc(type, n)

<p>
These method create a minimizer of type <tt>type</tt> for an
<tt>n</tt>-dimension function. The type is given by a string, or by a Ruby
constant.
</p>
<ul>
<li><tt>GSL::MultiMin::FdfMinimizer::CONJUGATE_FR</tt> or
<tt>&quot;conjugate_fr&quot;</tt>

</li>
<li><tt>GSL::MultiMin::FdfMinimizer::CONJUGATE_PR</tt> or
<tt>&quot;conjugate_pr&quot;</tt>

</li>
<li><tt>GSL::MultiMin::FdfMinimizer::VECTOR_BFGS</tt> or
<tt>&quot;vector_bfgs&quot;</tt>

</li>
<li><tt>GSL::MultiMin::FdfMinimizer::VECTOR_BFGS2</tt> or
<tt>&quot;vector_bfgs2&quot;</tt> (GSL-1.9 or later)

</li>
<li><tt>GSL::MultiMin::FdfMinimizer::STEEPEST_DESCENT</tt> or
<tt>&quot;steepest_descent&quot;</tt>

</li>
<li><tt>GSL::MultiMin::FMinimizer::NMSIMPLEX</tt> or
<tt>&quot;nmsimplex&quot;</tt>

</li>
<li><tt>GSL::MultiMin::FMinimizer::NMSIMPLEX2RAND</tt> or
<tt>&quot;nmsimplex2rand&quot;</tt> (GSL-1.13)

</li>
</ul>
<p>
ex:
</p>
<pre>
    include GSL::MultiMin
    m1 = FdfMinimizer.alloc(FdfMinimizer::CONJUGATE_FR, 2)
    m2 = FdfMinimizer.alloc(&quot;steepest_descent&quot;, 4)
    m3 = FMinimizer.alloc(FMinimizer::NMSIMPLEX, 3)
    m4 = FMinimizer.alloc(&quot;nmsimplex&quot;, 2)
</pre>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiMin::FdfMinimizer#set(func, x, step_size, tol)

<p>
This method initializes the minimizer <tt>self</tt> to minimize the
function <tt>fdf</tt> (the <tt>GSL::MultiMin::Function_fdf</tt> class, see
below) starting from the initial point <tt>x</tt> (<tt>GSL::Vector</tt>).
The size of the first trial step is given by <tt>step_size</tt>
(<tt>Vector</tt>). The accuracy of the line minimization is specified by
<tt>tol</tt>.
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiMin::FMinimizer#set(func, x, step_size)

<p>
This method initializes the minimizer <tt>self</tt> to minimize the
function <tt>func</tt>, starting from the initial point <tt>x</tt>
(Vector). The size of the initial trial steps is given in vector
<tt>step_size</tt>.
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiMin::FdfMinimizer#name

</li>
<li>GSL::MultiMin::FMinimizer#name

<p>
These return the name of the minimizer <tt>self</tt>.
</p>
</li>
</ul>
<h2><a href="../.././index.html"name="4"></a> Providing a function to minimize</h2>
<p>
You must provide a parametric function of <tt>n</tt> variables for the
minimizers to operate on. You may also need to provide a routine which
calculates the gradient of the function. In order to allow for general
parameters the functions are defined by the classes,
<tt>GSL::MultiMin::Function_fdf</tt> and <tt>GSL::MultiMin::Function</tt>.
</p>
<hr size="1"></hr><ul>
<li>GSL::MultiMin:Function_fdf.alloc(proc_f, proc_df, n)

</li>
<li>GSL::MultiMin:Function_fdf.alloc(proc_f, proc_df, proc_fdf, n)

</li>
<li>GSL::MultiMin:Function_fdf#set_procs(proc_f, proc_df)

</li>
<li>GSL::MultiMin:Function_fdf#set_procs(proc_f, proc_df, n)

</li>
<li>GSL::MultiMin:Function_fdf#set_procs(proc_f, proc_df, proc_fdf, n)

</li>
<li>GSL::MultiMin:Function_fdf#set_params(params)

<p>
See example below.
</p>
<pre>
  include GSL::MultiMin

  my_f = Proc.new { |v, params|
    x = v[0]; y = v[1]
    p0 = params[0]; p1 = params[1]
    10.0*(x - p0)*(x - p0) + 20.0*(y - p1)*(y - p1) + 30.0
  }

  my_df = Proc.new { |v, params, df|
    x = v[0]; y = v[1]
    p0 = params[0]; p1 = params[1]
    df[0] = 20.0*(x-p0)
    df[1] = 40.0*(y-p1)
  }

  my_func = Function_fdf.alloc(my_f, my_df, 2)
  my_func.set_params([1.0, 2.0])      # parameters
</pre>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiMin:Function.alloc(proc_f, n)

</li>
<li>GSL::MultiMin:Function#set_proc(proc_f)

</li>
<li>GSL::MultiMin:Function#set_proc(proc_f, n)

</li>
<li>GSL::MultiMin:Function#set_params(params)

<p>
See example below.
</p>
<pre>
  include GSL::MultiMin

  np = 2
  my_f = Proc.alloc { |v, params|
    x = v[0]; y = v[1]
    p0 = params[0]; p1 = params[1]
    10.0*(x - p0)*(x - p0) + 20.0*(y - p1)*(y - p1) + 30.0
  }

  my_func = Function.alloc(my_f, np)
  my_func.set_params([1.0, 2.0])      # parameters
</pre>
</li>
</ul>
<h2><a href="../.././index.html"name="5"></a> Iteration</h2>
<hr size="1"></hr><ul>
<li>GSL::MultiMin::FdfMinimizer#iterate

</li>
<li>GSL::MultiMin::FMinimizer#iterate

<p>
These methods perform a single iteration of the minimizer <tt>self</tt>. If
the iteration encounters an unexpected problem then an error code will be
returned. The minimizer maintains a current best estimate of the minimum at
all times. This information can be accessed with the following methods,
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiMin::FdfMinimizer#x

</li>
<li>GSL::MultiMin::FdfMinimizer#minimum

</li>
<li>GSL::MultiMin::FdfMinimizer#gradient

</li>
<li>GSL::MultiMin::FMinimizer#x

</li>
<li>GSL::MultiMin::FMinimizer#minimum

</li>
<li>GSL::MultiMin::FMinimizer#size

<p>
These method return the current best estimate of the location of the
minimum, the value of the function at that point, its gradient, and
minimizer specific characteristic size for the minimizer <tt>self</tt>.
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiMin::FdfMinimizer#restart

<p>
This method resets the minimizer <tt>self</tt> to use the current point as
a new starting point.
</p>
</li>
</ul>
<h2><a href="../.././index.html"name="6"></a> Stopping Criteria</h2>
<p>
A minimization procedure should stop when one of the following conditions
is true:
</p>
<ul>
<li>A minimum has been found to within the user-specified precision.

</li>
<li>A user-specified maximum number of iterations has been reached.

</li>
<li>An error has occurred.

</li>
</ul>
<p>
The handling of these conditions is under user control. The methods below
allow the user to test the precision of the current result.
</p>
<hr size="1"></hr><ul>
<li>GSL::MultiMin::FdfMinimizer#test_gradient(epsabs)

</li>
<li>GSL::MultiMin::FdfMinimizer.test_gradient(g, epsabs)

<p>
These method test the norm of the gradient <tt>g</tt> against the absolute
tolerance <tt>epsabs</tt>. The gradient of a multidimensional function goes
to zero at a minimum. The tests return <tt>GSL::SUCCESS</tt> if the
following condition is achieved,
</p>
<pre>
  |g| &lt; epsabs
</pre>
<p>
and returns <tt>GSL::CONTINUE</tt> otherwise. A suitable choice of
<tt>epsabs</tt> can be made from the desired accuracy in the function for
small variations in <tt>x</tt>. The relationship between these quantities
is given by <tt>\delta f = g \delta x</tt>.
</p>
</li>
</ul>
<hr size="1"></hr><ul>
<li>GSL::MultiMin::FdfMinimizer#test_size(epsabs)

</li>
<li>GSL::MultiMin::FdfMinimizer.test_size(size, epsabs)

<p>
These method test the minimizer specific characteristic <tt>size</tt> (if
applicable to the used minimizer) against absolute tolerance
<tt>epsabs</tt>. The tests return (<tt>GSL::SUCCESS</tt> if the size is
smaller than tolerance, otherwise <tt>GSL::CONTINUE</tt> is returned.
</p>
</li>
</ul>
<h2><a href="../.././index.html"name="7"></a> Examples</h2>
<h3><a href="../.././index.html"name="7.1"></a> FdfMinimizer</h3>
<pre>
     #!/usr/bin/env ruby
     require(&quot;gsl&quot;)
     include GSL::MultiMin

     my_f = Proc.new { |v, params|
       x = v[0]; y = v[1]
       p0 = params[0]; p1 = params[1]
       10.0*(x - p0)*(x - p0) + 20.0*(y - p1)*(y - p1) + 30.0
     }

     my_df = Proc.new { |v, params, df|
       x = v[0]; y = v[1]
       p0 = params[0]; p1 = params[1]
       df[0] = 20.0*(x-p0)
       df[1] = 40.0*(y-p1)
     }

     my_func = Function_fdf.alloc(my_f, my_df, 2)
     my_func.set_params([1.0, 2.0])      # parameters

     x = Vector.alloc(5.0, 7.0)          # starting point

     minimizer = FdfMinimizer.alloc(&quot;conjugate_fr&quot;, 2)
     minimizer.set(my_func, x, 0.01, 1e-4)

     iter = 0
     begin
       iter += 1
       status = minimizer.iterate()
       status = minimizer.test_gradient(1e-3)
       if status == GSL::SUCCESS
         puts(&quot;Minimum found at&quot;)
       end
       x = minimizer.x
       f = minimizer.f
       printf(&quot;%5d %.5f %.5f %10.5f\n&quot;, iter, x[0], x[1], f)
     end while status == GSL::CONTINUE and iter &lt; 100
</pre>
<h3><a href="../.././index.html"name="7.2"></a> FMinimizer</h3>
<pre>
     #!/usr/bin/env ruby
     require(&quot;gsl&quot;)
     include GSL::MultiMin

     np = 2

     my_f = Proc.new { |v, params|
       x = v[0]; y = v[1]
       p0 = params[0]; p1 = params[1]
       10.0*(x - p0)*(x - p0) + 20.0*(y - p1)*(y - p1) + 30.0
     }

     my_func = Function.alloc(my_f, np)
     my_func.set_params([1.0, 2.0])      # parameters

     x = Vector.alloc([5, 7])
     ss = Vector.alloc(np)
     ss.set_all(1.0)

     minimizer = FMinimizer.alloc(&quot;nmsimplex&quot;, np)
     minimizer.set(my_func, x, ss)

     iter = 0
     begin
       iter += 1
       status = minimizer.iterate()
       status = minimizer.test_size(1e-2)
       if status == GSL::SUCCESS
         puts(&quot;converged to minimum at&quot;)
       end
       x = minimizer.x
       printf(&quot;%5d &quot;, iter);
       for i in 0...np do
         printf(&quot;%10.3e &quot;, x[i])
       end
       printf(&quot;f() = %7.3f size = %.3f\n&quot;, minimizer.fval, minimizer.size);
     end while status == GSL::CONTINUE and iter &lt; 100
</pre>
<p>
<a href="multiroot_rdoc.html">prev</a> <a href="fit_rdoc.html">next</a>
</p>
<p>
<a href="ref_rdoc.html">Reference index</a> <a
href="index_rdoc.html">top</a>
</p>

    </div>


   </div>


  </div>


    <!-- if includes -->

    <div id="section">





      


    <!-- if method_list -->


  </div>


<div id="validator-badges">
  <p><small><a href="http://validator.w3.org/check/referer">[Validate]</a></small></p>
</div>

</body>
</html>